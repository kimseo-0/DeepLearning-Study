{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "852ea2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torchvision.transforms import transforms         # ì´ë¯¸ì§€ ë³€í˜•\n",
    "from torch.utils.data.dataloader import DataLoader  # train - test ë¶„ë¦¬\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f39cff",
   "metadata": {},
   "source": [
    "## 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "35e72d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # Tensor ë°ì´í„° íƒ€ìž…ìœ¼ë¡œ ë³€ê²½\n",
    "    transforms.Resize((32, 32)), # ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆë¥¼ 28 > 32 ë¡œ ë³€í˜• (renet ëª¨ë¸ì—ì„œ 32 ì‚¬ì´ì¦ˆ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì—)\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.RandomCrop((32, 32), padding=4),\n",
    "    transforms.Normalize((0.5),(1.0)) # í‰ê· , í‘œì¤€íŽ¸ì°¨ | ì‹¤ì „ì—ì„œëŠ” ì „ì²´ ë°ì´í„°ì…‹ì˜ í‰ê· ê³¼ í‘œì¤€íŽ¸ì°¨ë¥¼ ê³„ì‚°í•˜ì—¬ ë„£ìŠµë‹ˆë‹¤\n",
    "])\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # Tensor ë°ì´í„° íƒ€ìž…ìœ¼ë¡œ ë³€ê²½\n",
    "    transforms.Resize((32, 32)), # ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆë¥¼ 28 > 32 ë¡œ ë³€í˜• (renet ëª¨ë¸ì—ì„œ 32 ì‚¬ì´ì¦ˆ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì—)\n",
    "    transforms.Normalize((0.5),(1.0)) # í‰ê· , í‘œì¤€íŽ¸ì°¨ | ì‹¤ì „ì—ì„œëŠ” ì „ì²´ ë°ì´í„°ì…‹ì˜ í‰ê· ê³¼ í‘œì¤€íŽ¸ì°¨ë¥¼ ê³„ì‚°í•˜ì—¬ ë„£ìŠµë‹ˆë‹¤\n",
    "])\n",
    "\n",
    "train_data = MNIST(root='./', train=True, download=True, transform=data_transform) \n",
    "test_data = MNIST(root='./', train=False, download=True, transform=data_transform) \n",
    "# transform : ë°ì´í„° ì „ì²˜ë¦¬í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e7a302",
   "metadata": {},
   "source": [
    "## 2. ë°ì´í„° í™•ì¸í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dd93554c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b01d39e",
   "metadata": {},
   "source": [
    "## 3. ë°°ì¹˜ ì‚¬ì´ì¦ˆì— ë”°ë¥¸ ë°ì´í„° ë¶„ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b61d6ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True) \n",
    "test_loader = DataLoader(test_data, batch_size=32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "239cd32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "data, label = next(iter(train_loader))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6196a2ba",
   "metadata": {},
   "source": [
    "## 4. ëª¨ë¸ ì •ì˜í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5fe67ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lenet(nn.Module): # ðŸ“Œ ëª¨ë¸ëª…(nn.Module) , ê´„í˜¸ ì•ˆì— nn.Module ì„ ë°˜ë“œì‹œ ì ì„ ê²ƒ\n",
    "    def __init__(self): # ðŸ“Œ __init__(self) ë¥¼ ë°˜ë“œì‹œ í•´ì•¼í•¨\n",
    "        super(Lenet, self).__init__() # ðŸ“Œ super(ëª¨ë¸ëª…, self).__init__() ë°˜ë“œì‹œ í•´ì•¼í•¨\n",
    "\n",
    "        # convolutions í•©ì„±ê³±ì„ ìœ„í•œ í•¨ìˆ˜ë“¤ì„ ì¤€ë¹„í•œë‹¤\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1)\n",
    "\n",
    "        # fully connection \n",
    "        self.fc1 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc2 = nn.Linear(in_features=84, out_features=10) \n",
    "        # â­â­ ë§ˆì§€ë§‰ fcí•¨ìˆ˜ì˜ out_features ì—ëŠ” ë‚´ê°€ ë¶„ë¥˜í•˜ê³  ì‹¶ì€ ì •ë‹µì„ ì ì„ê²ƒ!!\n",
    "    \n",
    "    # â­ ìˆœì „íŒŒë¥¼ í•˜ëŠ” í•¨ìˆ˜\n",
    "    def forward(self, x):  # ðŸ“Œ forward ì•ˆì— self ë¥¼ ë°˜ë“œì‹œ ì ì–´ì•¼í•¨\n",
    "        x = self.conv1(x)                          \n",
    "        x = F.tanh(x) # í™œì„±í•¨ìˆ˜\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2) # ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆ ì¶•ì†Œ\n",
    "\n",
    "        x = self.conv2(x)                            \n",
    "        x = F.tanh(x) # í™œì„±í•¨ìˆ˜\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2) # ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆ ì¶•ì†Œ\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.tanh(x)\n",
    "\n",
    "        x = torch.reshape(x, (-1, 120)) # ì´ë¯¸ì§€ í‰íƒ„í™”\n",
    "\n",
    "        x = self.fc1(x)             # ì„ í˜•í•¨ìˆ˜\n",
    "        x = F.tanh(x)               # í™œì„±í•¨ìˆ˜\n",
    "\n",
    "        x = self.fc2(x)             # ì„ í˜•í•¨ìˆ˜\n",
    "        x = F.tanh(x)               # í™œì„±í•¨ìˆ˜ \n",
    "        # Renet ëª¨ë¸ì´ ì˜›ë‚  ëª¨ë¸ì´ë¼ tanh í™œì„±í•¨ìˆ˜ë¥¼ ë§ˆì§€ë§‰ì— ì‚¬ìš© ì¤‘ì¸ë°\n",
    "        # ìµœê·¼ íŠ¸ë Œë“œëŠ” CrossEntrophyë¥¼ ì†ì‹¤í•¨ìˆ˜ë¡œ ì‚¬ìš©í•  ê²½ìš° ë§ˆì§€ë§‰ì— í™œì„±í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "208f7059",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lenet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6d7780b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models.resnet import resnet34\n",
    "model = resnet34()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5d60297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(in_features=512, out_features=10, bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de39a36",
   "metadata": {},
   "source": [
    "## 5. ëª¨ë¸ í•™ìŠµí•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "89c9ec86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "â”œâ”€Conv2d: 1-1                            9,408\n",
      "â”œâ”€BatchNorm2d: 1-2                       128\n",
      "â”œâ”€ReLU: 1-3                              --\n",
      "â”œâ”€MaxPool2d: 1-4                         --\n",
      "â”œâ”€Sequential: 1-5                        --\n",
      "|    â””â”€BasicBlock: 2-1                   --\n",
      "|    |    â””â”€Conv2d: 3-1                  36,864\n",
      "|    |    â””â”€BatchNorm2d: 3-2             128\n",
      "|    |    â””â”€ReLU: 3-3                    --\n",
      "|    |    â””â”€Conv2d: 3-4                  36,864\n",
      "|    |    â””â”€BatchNorm2d: 3-5             128\n",
      "|    â””â”€BasicBlock: 2-2                   --\n",
      "|    |    â””â”€Conv2d: 3-6                  36,864\n",
      "|    |    â””â”€BatchNorm2d: 3-7             128\n",
      "|    |    â””â”€ReLU: 3-8                    --\n",
      "|    |    â””â”€Conv2d: 3-9                  36,864\n",
      "|    |    â””â”€BatchNorm2d: 3-10            128\n",
      "|    â””â”€BasicBlock: 2-3                   --\n",
      "|    |    â””â”€Conv2d: 3-11                 36,864\n",
      "|    |    â””â”€BatchNorm2d: 3-12            128\n",
      "|    |    â””â”€ReLU: 3-13                   --\n",
      "|    |    â””â”€Conv2d: 3-14                 36,864\n",
      "|    |    â””â”€BatchNorm2d: 3-15            128\n",
      "â”œâ”€Sequential: 1-6                        --\n",
      "|    â””â”€BasicBlock: 2-4                   --\n",
      "|    |    â””â”€Conv2d: 3-16                 73,728\n",
      "|    |    â””â”€BatchNorm2d: 3-17            256\n",
      "|    |    â””â”€ReLU: 3-18                   --\n",
      "|    |    â””â”€Conv2d: 3-19                 147,456\n",
      "|    |    â””â”€BatchNorm2d: 3-20            256\n",
      "|    |    â””â”€Sequential: 3-21             8,448\n",
      "|    â””â”€BasicBlock: 2-5                   --\n",
      "|    |    â””â”€Conv2d: 3-22                 147,456\n",
      "|    |    â””â”€BatchNorm2d: 3-23            256\n",
      "|    |    â””â”€ReLU: 3-24                   --\n",
      "|    |    â””â”€Conv2d: 3-25                 147,456\n",
      "|    |    â””â”€BatchNorm2d: 3-26            256\n",
      "|    â””â”€BasicBlock: 2-6                   --\n",
      "|    |    â””â”€Conv2d: 3-27                 147,456\n",
      "|    |    â””â”€BatchNorm2d: 3-28            256\n",
      "|    |    â””â”€ReLU: 3-29                   --\n",
      "|    |    â””â”€Conv2d: 3-30                 147,456\n",
      "|    |    â””â”€BatchNorm2d: 3-31            256\n",
      "|    â””â”€BasicBlock: 2-7                   --\n",
      "|    |    â””â”€Conv2d: 3-32                 147,456\n",
      "|    |    â””â”€BatchNorm2d: 3-33            256\n",
      "|    |    â””â”€ReLU: 3-34                   --\n",
      "|    |    â””â”€Conv2d: 3-35                 147,456\n",
      "|    |    â””â”€BatchNorm2d: 3-36            256\n",
      "â”œâ”€Sequential: 1-7                        --\n",
      "|    â””â”€BasicBlock: 2-8                   --\n",
      "|    |    â””â”€Conv2d: 3-37                 294,912\n",
      "|    |    â””â”€BatchNorm2d: 3-38            512\n",
      "|    |    â””â”€ReLU: 3-39                   --\n",
      "|    |    â””â”€Conv2d: 3-40                 589,824\n",
      "|    |    â””â”€BatchNorm2d: 3-41            512\n",
      "|    |    â””â”€Sequential: 3-42             33,280\n",
      "|    â””â”€BasicBlock: 2-9                   --\n",
      "|    |    â””â”€Conv2d: 3-43                 589,824\n",
      "|    |    â””â”€BatchNorm2d: 3-44            512\n",
      "|    |    â””â”€ReLU: 3-45                   --\n",
      "|    |    â””â”€Conv2d: 3-46                 589,824\n",
      "|    |    â””â”€BatchNorm2d: 3-47            512\n",
      "|    â””â”€BasicBlock: 2-10                  --\n",
      "|    |    â””â”€Conv2d: 3-48                 589,824\n",
      "|    |    â””â”€BatchNorm2d: 3-49            512\n",
      "|    |    â””â”€ReLU: 3-50                   --\n",
      "|    |    â””â”€Conv2d: 3-51                 589,824\n",
      "|    |    â””â”€BatchNorm2d: 3-52            512\n",
      "|    â””â”€BasicBlock: 2-11                  --\n",
      "|    |    â””â”€Conv2d: 3-53                 589,824\n",
      "|    |    â””â”€BatchNorm2d: 3-54            512\n",
      "|    |    â””â”€ReLU: 3-55                   --\n",
      "|    |    â””â”€Conv2d: 3-56                 589,824\n",
      "|    |    â””â”€BatchNorm2d: 3-57            512\n",
      "|    â””â”€BasicBlock: 2-12                  --\n",
      "|    |    â””â”€Conv2d: 3-58                 589,824\n",
      "|    |    â””â”€BatchNorm2d: 3-59            512\n",
      "|    |    â””â”€ReLU: 3-60                   --\n",
      "|    |    â””â”€Conv2d: 3-61                 589,824\n",
      "|    |    â””â”€BatchNorm2d: 3-62            512\n",
      "|    â””â”€BasicBlock: 2-13                  --\n",
      "|    |    â””â”€Conv2d: 3-63                 589,824\n",
      "|    |    â””â”€BatchNorm2d: 3-64            512\n",
      "|    |    â””â”€ReLU: 3-65                   --\n",
      "|    |    â””â”€Conv2d: 3-66                 589,824\n",
      "|    |    â””â”€BatchNorm2d: 3-67            512\n",
      "â”œâ”€Sequential: 1-8                        --\n",
      "|    â””â”€BasicBlock: 2-14                  --\n",
      "|    |    â””â”€Conv2d: 3-68                 1,179,648\n",
      "|    |    â””â”€BatchNorm2d: 3-69            1,024\n",
      "|    |    â””â”€ReLU: 3-70                   --\n",
      "|    |    â””â”€Conv2d: 3-71                 2,359,296\n",
      "|    |    â””â”€BatchNorm2d: 3-72            1,024\n",
      "|    |    â””â”€Sequential: 3-73             132,096\n",
      "|    â””â”€BasicBlock: 2-15                  --\n",
      "|    |    â””â”€Conv2d: 3-74                 2,359,296\n",
      "|    |    â””â”€BatchNorm2d: 3-75            1,024\n",
      "|    |    â””â”€ReLU: 3-76                   --\n",
      "|    |    â””â”€Conv2d: 3-77                 2,359,296\n",
      "|    |    â””â”€BatchNorm2d: 3-78            1,024\n",
      "|    â””â”€BasicBlock: 2-16                  --\n",
      "|    |    â””â”€Conv2d: 3-79                 2,359,296\n",
      "|    |    â””â”€BatchNorm2d: 3-80            1,024\n",
      "|    |    â””â”€ReLU: 3-81                   --\n",
      "|    |    â””â”€Conv2d: 3-82                 2,359,296\n",
      "|    |    â””â”€BatchNorm2d: 3-83            1,024\n",
      "â”œâ”€AdaptiveAvgPool2d: 1-9                 --\n",
      "â”œâ”€Linear: 1-10                           5,130\n",
      "=================================================================\n",
      "Total params: 21,289,802\n",
      "Trainable params: 21,289,802\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "â”œâ”€Conv2d: 1-1                            9,408\n",
       "â”œâ”€BatchNorm2d: 1-2                       128\n",
       "â”œâ”€ReLU: 1-3                              --\n",
       "â”œâ”€MaxPool2d: 1-4                         --\n",
       "â”œâ”€Sequential: 1-5                        --\n",
       "|    â””â”€BasicBlock: 2-1                   --\n",
       "|    |    â””â”€Conv2d: 3-1                  36,864\n",
       "|    |    â””â”€BatchNorm2d: 3-2             128\n",
       "|    |    â””â”€ReLU: 3-3                    --\n",
       "|    |    â””â”€Conv2d: 3-4                  36,864\n",
       "|    |    â””â”€BatchNorm2d: 3-5             128\n",
       "|    â””â”€BasicBlock: 2-2                   --\n",
       "|    |    â””â”€Conv2d: 3-6                  36,864\n",
       "|    |    â””â”€BatchNorm2d: 3-7             128\n",
       "|    |    â””â”€ReLU: 3-8                    --\n",
       "|    |    â””â”€Conv2d: 3-9                  36,864\n",
       "|    |    â””â”€BatchNorm2d: 3-10            128\n",
       "|    â””â”€BasicBlock: 2-3                   --\n",
       "|    |    â””â”€Conv2d: 3-11                 36,864\n",
       "|    |    â””â”€BatchNorm2d: 3-12            128\n",
       "|    |    â””â”€ReLU: 3-13                   --\n",
       "|    |    â””â”€Conv2d: 3-14                 36,864\n",
       "|    |    â””â”€BatchNorm2d: 3-15            128\n",
       "â”œâ”€Sequential: 1-6                        --\n",
       "|    â””â”€BasicBlock: 2-4                   --\n",
       "|    |    â””â”€Conv2d: 3-16                 73,728\n",
       "|    |    â””â”€BatchNorm2d: 3-17            256\n",
       "|    |    â””â”€ReLU: 3-18                   --\n",
       "|    |    â””â”€Conv2d: 3-19                 147,456\n",
       "|    |    â””â”€BatchNorm2d: 3-20            256\n",
       "|    |    â””â”€Sequential: 3-21             8,448\n",
       "|    â””â”€BasicBlock: 2-5                   --\n",
       "|    |    â””â”€Conv2d: 3-22                 147,456\n",
       "|    |    â””â”€BatchNorm2d: 3-23            256\n",
       "|    |    â””â”€ReLU: 3-24                   --\n",
       "|    |    â””â”€Conv2d: 3-25                 147,456\n",
       "|    |    â””â”€BatchNorm2d: 3-26            256\n",
       "|    â””â”€BasicBlock: 2-6                   --\n",
       "|    |    â””â”€Conv2d: 3-27                 147,456\n",
       "|    |    â””â”€BatchNorm2d: 3-28            256\n",
       "|    |    â””â”€ReLU: 3-29                   --\n",
       "|    |    â””â”€Conv2d: 3-30                 147,456\n",
       "|    |    â””â”€BatchNorm2d: 3-31            256\n",
       "|    â””â”€BasicBlock: 2-7                   --\n",
       "|    |    â””â”€Conv2d: 3-32                 147,456\n",
       "|    |    â””â”€BatchNorm2d: 3-33            256\n",
       "|    |    â””â”€ReLU: 3-34                   --\n",
       "|    |    â””â”€Conv2d: 3-35                 147,456\n",
       "|    |    â””â”€BatchNorm2d: 3-36            256\n",
       "â”œâ”€Sequential: 1-7                        --\n",
       "|    â””â”€BasicBlock: 2-8                   --\n",
       "|    |    â””â”€Conv2d: 3-37                 294,912\n",
       "|    |    â””â”€BatchNorm2d: 3-38            512\n",
       "|    |    â””â”€ReLU: 3-39                   --\n",
       "|    |    â””â”€Conv2d: 3-40                 589,824\n",
       "|    |    â””â”€BatchNorm2d: 3-41            512\n",
       "|    |    â””â”€Sequential: 3-42             33,280\n",
       "|    â””â”€BasicBlock: 2-9                   --\n",
       "|    |    â””â”€Conv2d: 3-43                 589,824\n",
       "|    |    â””â”€BatchNorm2d: 3-44            512\n",
       "|    |    â””â”€ReLU: 3-45                   --\n",
       "|    |    â””â”€Conv2d: 3-46                 589,824\n",
       "|    |    â””â”€BatchNorm2d: 3-47            512\n",
       "|    â””â”€BasicBlock: 2-10                  --\n",
       "|    |    â””â”€Conv2d: 3-48                 589,824\n",
       "|    |    â””â”€BatchNorm2d: 3-49            512\n",
       "|    |    â””â”€ReLU: 3-50                   --\n",
       "|    |    â””â”€Conv2d: 3-51                 589,824\n",
       "|    |    â””â”€BatchNorm2d: 3-52            512\n",
       "|    â””â”€BasicBlock: 2-11                  --\n",
       "|    |    â””â”€Conv2d: 3-53                 589,824\n",
       "|    |    â””â”€BatchNorm2d: 3-54            512\n",
       "|    |    â””â”€ReLU: 3-55                   --\n",
       "|    |    â””â”€Conv2d: 3-56                 589,824\n",
       "|    |    â””â”€BatchNorm2d: 3-57            512\n",
       "|    â””â”€BasicBlock: 2-12                  --\n",
       "|    |    â””â”€Conv2d: 3-58                 589,824\n",
       "|    |    â””â”€BatchNorm2d: 3-59            512\n",
       "|    |    â””â”€ReLU: 3-60                   --\n",
       "|    |    â””â”€Conv2d: 3-61                 589,824\n",
       "|    |    â””â”€BatchNorm2d: 3-62            512\n",
       "|    â””â”€BasicBlock: 2-13                  --\n",
       "|    |    â””â”€Conv2d: 3-63                 589,824\n",
       "|    |    â””â”€BatchNorm2d: 3-64            512\n",
       "|    |    â””â”€ReLU: 3-65                   --\n",
       "|    |    â””â”€Conv2d: 3-66                 589,824\n",
       "|    |    â””â”€BatchNorm2d: 3-67            512\n",
       "â”œâ”€Sequential: 1-8                        --\n",
       "|    â””â”€BasicBlock: 2-14                  --\n",
       "|    |    â””â”€Conv2d: 3-68                 1,179,648\n",
       "|    |    â””â”€BatchNorm2d: 3-69            1,024\n",
       "|    |    â””â”€ReLU: 3-70                   --\n",
       "|    |    â””â”€Conv2d: 3-71                 2,359,296\n",
       "|    |    â””â”€BatchNorm2d: 3-72            1,024\n",
       "|    |    â””â”€Sequential: 3-73             132,096\n",
       "|    â””â”€BasicBlock: 2-15                  --\n",
       "|    |    â””â”€Conv2d: 3-74                 2,359,296\n",
       "|    |    â””â”€BatchNorm2d: 3-75            1,024\n",
       "|    |    â””â”€ReLU: 3-76                   --\n",
       "|    |    â””â”€Conv2d: 3-77                 2,359,296\n",
       "|    |    â””â”€BatchNorm2d: 3-78            1,024\n",
       "|    â””â”€BasicBlock: 2-16                  --\n",
       "|    |    â””â”€Conv2d: 3-79                 2,359,296\n",
       "|    |    â””â”€BatchNorm2d: 3-80            1,024\n",
       "|    |    â””â”€ReLU: 3-81                   --\n",
       "|    |    â””â”€Conv2d: 3-82                 2,359,296\n",
       "|    |    â””â”€BatchNorm2d: 3-83            1,024\n",
       "â”œâ”€AdaptiveAvgPool2d: 1-9                 --\n",
       "â”œâ”€Linear: 1-10                           5,130\n",
       "=================================================================\n",
       "Total params: 21,289,802\n",
       "Trainable params: 21,289,802\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, input_size=(1, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "257dc4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ëª¨ë‘ gpuì— ì˜¬ë¼ê°€ê²Œ í•˜ëŠ” ì½”ë“œ\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "554f785c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 3, 7, 7], expected input[32, 1, 32, 32] to have 3 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     13\u001b[39m optim.zero_grad() \u001b[38;5;66;03m# ðŸ“Œ ìµœì í™” í•¨ìˆ˜ë¥¼ ì´ˆê¸°í™” í•´ì•¼í•¨ (í•œ ë²ˆ í•™ìŠµì‹œ ë§ˆë‹¤)\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# â­â­ CNN ì˜ ê²½ìš°ëŠ” ì´ë¯¸ì§€ì˜ ì±„ë„ ìˆ˜ë§Œ ë§žì¶”ë©´ ëœë‹¤\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Renet ì˜ ê²½ìš° 1 ì±„ë„ ì´ë¯¸ì§€ë§Œ ë˜ë©´ ëœë‹¤!\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# 1) ìˆœì „íŒŒ\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m pred = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# â­ë°ì´í„° ìœ„ì¹˜ ì²´í¬\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# 2) ì†ì‹¤ ê³„ì‚°\u001b[39;00m\n\u001b[32m     21\u001b[39m loss = criterion(pred, label.to(device)) \u001b[38;5;66;03m# â­ë°ì´í„° ìœ„ì¹˜ ì²´í¬\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Potenup\\DeepLearning-Study\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Potenup\\DeepLearning-Study\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Potenup\\DeepLearning-Study\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[39m, in \u001b[36mResNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Potenup\\DeepLearning-Study\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:268\u001b[39m, in \u001b[36mResNet._forward_impl\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Tensor:\n\u001b[32m    267\u001b[39m     \u001b[38;5;66;03m# See note [TorchScript super()]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    269\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.bn1(x)\n\u001b[32m    270\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.relu(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Potenup\\DeepLearning-Study\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Potenup\\DeepLearning-Study\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Potenup\\DeepLearning-Study\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Potenup\\DeepLearning-Study\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:543\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    533\u001b[39m         F.pad(\n\u001b[32m    534\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    541\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    542\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Given groups=1, weight of size [64, 3, 7, 7], expected input[32, 1, 32, 32] to have 3 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "lr = 1e-3                               # âœ… ëŸ¬ë‹ë ˆì´íŠ¸: ì¼ë°˜ì ìœ¼ë¡œ 0.001 ~ 0.003\n",
    "optim = Adam(model.parameters(), lr=lr) # íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ ìµœì í™” ì•Œê³ ë¦¬ì¦˜\n",
    "epochs = 10                             # âœ… í•™ìŠµ ë°˜ë³µ íšŸìˆ˜\n",
    "criterion = nn.CrossEntropyLoss()       # âœ… ì†ì‹¤ í•¨ìˆ˜ : ë¶„ë¥˜ëª¨ë¸ - nn.CrossEntropyLoss() / ë‹¤ë¥¸ ëª¨ë¸ - nn.MSELoss\n",
    "\n",
    "step = 0\n",
    "for epoch in range(epochs):\n",
    "    # data : 32ê°œì˜ ì´ë¯¸ì§€ ë°ì´í„° / label : 32ê°œì˜ ì´ë¯¸ì§€ì˜ ì •ë‹µ ë°ì´í„°\n",
    "    for data, label in train_loader: # [(data, label)]\n",
    "        optim.zero_grad() # ðŸ“Œ ìµœì í™” í•¨ìˆ˜ë¥¼ ì´ˆê¸°í™” í•´ì•¼í•¨ (í•œ ë²ˆ í•™ìŠµì‹œ ë§ˆë‹¤)\n",
    "\n",
    "        # â­â­ CNN ì˜ ê²½ìš°ëŠ” ì´ë¯¸ì§€ì˜ ì±„ë„ ìˆ˜ë§Œ ë§žì¶”ë©´ ëœë‹¤\n",
    "        # Renet ì˜ ê²½ìš° 1 ì±„ë„ ì´ë¯¸ì§€ë§Œ ë˜ë©´ ëœë‹¤!\n",
    "        # 1) ìˆœì „íŒŒ\n",
    "        pred = model(data.to(device)) # â­ë°ì´í„° ìœ„ì¹˜ ì²´í¬\n",
    "\n",
    "        # 2) ì†ì‹¤ ê³„ì‚°\n",
    "        loss = criterion(pred, label.to(device)) # â­ë°ì´í„° ìœ„ì¹˜ ì²´í¬\n",
    "\n",
    "        # 3) ì—­ì „íŒŒ\n",
    "        loss.backward()\n",
    "        optim.step() # 4) íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸\n",
    "\n",
    "        # tensorboardì— ë°ì´í„° ì¶”ê°€\n",
    "        writer.add_scalar(\"Loss/train\", loss.item(), step)\n",
    "        step += 1\n",
    "\n",
    "    print(f\"{epoch + 1} loss : {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea6aa91",
   "metadata": {},
   "source": [
    "## 6. ëª¨ë¸ ì €ìž¥í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508bd18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ðŸ“Œ â­â­â­ í•™ìŠµì‹œí‚¨ ëª¨ë¸ì´ ë‚ ë¼ê°€ì§€ ì•Šë„ë¡ ë°˜ë“œì‹œ ê¼­ê¼­ ì €ìž¥í•˜ìž\n",
    "# import joblib\n",
    "\n",
    "# # ëª¨ë¸ ì €ìž¥\n",
    "# joblib.dump(model, 'models/number_image_cnn_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd2ffea",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/number_image_resnet34_model.pth') # ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë§Œ ì €ìž¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517f940f",
   "metadata": {},
   "source": [
    "## 7. ëª¨ë¸ í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8ba077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "import joblib\n",
    "model = joblib.load('models/number_image_cnn_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aefd996",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() # ðŸ“Œ ëª¨ë¸ì„ ì¶”ë¡ ìš©ìœ¼ë¡œ ì „í™˜í•˜ê²Œ í•˜ëŠ” ì½”ë“œ\n",
    "\n",
    "# ì¶”ê°€ ìž‘ì„± ì½”ë“œ\n",
    "# falut_data = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_corr = 0\n",
    "    for images, labels in test_loader:\n",
    "        X = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        preds = model(X)\n",
    "        _, pred = torch.max(preds.data, dim = 1)\n",
    "        \n",
    "        result = (pred == labels)\n",
    "        total_corr += (result).sum().item()\n",
    "\n",
    "        # ì¶”ê°€ ìž‘ì„± ì½”ë“œ\n",
    "        # for i, re in enumerate(result):\n",
    "        #     if re == False:\n",
    "        #         falut_data.append({\n",
    "        #             'image' : images[i],\n",
    "        #             'pred' : pred[i],\n",
    "        #             'label' :labels[i]\n",
    "        #         })\n",
    "\n",
    "print(f'ì •í™•ë„ : {total_corr / len(test_data.targets)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fb2674",
   "metadata": {},
   "source": [
    "## 8. ëª¨ë¸ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe08a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "image_path = 'images/4.jpg'\n",
    "\n",
    "# 1) ì´ë¯¸ì§€ ë³€í™˜(transform) íŒŒì´í”„ë¼ì¸ ì •ì˜\n",
    "# PyTorch ëª¨ë¸ì— ìž…ë ¥í•˜ê¸° ìœ„í•´ ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì„ ì •ì˜\n",
    "# ToTensor()ëŠ” PIL Imageë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜í•˜ë©°, í”½ì…€ ê°’ì„ [0, 1] ë²”ìœ„ë¡œ ì •ê·œí™”\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),              # ì´ë¯¸ì§€ë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜\n",
    "    transforms.Grayscale(),             # ì´ë¯¸ì§€ë¥¼ í‘ë°±ìœ¼ë¡œ ë§Œë“ ë‹¤\n",
    "    transforms.Resize((32, 32)),        # ì´ë¯¸ì§€ë¥¼ ë¦¬ì‚¬ì´ì¦ˆ\n",
    "    transforms.Normalize((0.5),(1.0))   # í‰ê· , í‘œì¤€íŽ¸ì°¨ë¡œ ì •ê·œí™” í•œë‹¤\n",
    "])\n",
    "\n",
    "with Image.open(image_path) as image:\n",
    "        print(f\"PIL Image í¬ê¸°: {image.size}\")\n",
    "        print(f\"PIL Image ëª¨ë“œ: {image.mode}\")\n",
    "\n",
    "        image = image.convert('L')\n",
    "        \n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "        # 2) ì •ì˜í•œ ë³€í™˜(transform)ì„ ì´ë¯¸ì§€ì— ì ìš©\n",
    "        tensor_image = transform(image)\n",
    "\n",
    "print(\"\\nì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜ ì™„ë£Œ:\")\n",
    "print(f\"í…ì„œ í¬ê¸°(size): {tensor_image.size}\")\n",
    "print(f\"í…ì„œ ë°ì´í„° íƒ€ìž…: {tensor_image.dtype}\")\n",
    "\n",
    "# 3) ëª¨ë¸ ì˜ˆì¸¡\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "# â­â­â­ 0ë²ˆì§¸ì— ê°•ì œë¡œ ì°¨ì›ì„ í•˜ë‚˜ ì¶”ê°€í•œë‹¤\n",
    "# ì™œ? ì´ ëª¨ë¸ì—ëŠ” 4ì°¨ì›ë°ì´í„°ê°€ ë“¤ì–´ê°€ì•¼í•˜ë‹ˆê¹Œ\n",
    "# ê¸°ì¡´ì—ëŠ” 32ê°œì˜ ì´ë¯¸ì§€ì— ëŒ€í•´ì„œ 1ì±„ë„ì˜ 32 x 32 ì´ë¯¸ì§€ê°€ ë‹´ê¸´\n",
    "# (32, 1, 32, 32) í˜•íƒœì˜ ë°ì´í„°ë¥¼ ëª¨ë¸ì— ë„£ì—ˆë‹¤\n",
    "\n",
    "# ì§€ê¸ˆì€ 1ê°œì˜ ì´ë¯¸ì§€ì— ëŒ€í•´ì„œ 1ì±„ë„ì˜ 32 32 ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ì— ë„£ê³ ì‹¶ìœ¼ë‹ˆ\n",
    "# (1, 1, 32, 32) í˜•íƒœì˜ ë°ì´í„°ë¥¼ ë„£ìœ¼ë©´ ëœë‹¤\n",
    "tensor_image = tensor_image.unsqueeze(dim=0)\n",
    "preds = model(tensor_image.to(device))\n",
    "_, pred = torch.max(preds.data, dim=1)\n",
    "print(f\"ì˜ˆì¸¡ ê²°ê³¼: {pred.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning-Study (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
