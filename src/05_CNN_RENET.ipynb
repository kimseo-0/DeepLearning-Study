{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "852ea2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torchvision.transforms import transforms         # 이미지 변형\n",
    "from torch.utils.data.dataloader import DataLoader  # train - test 분리\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f39cff",
   "metadata": {},
   "source": [
    "## 1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e72d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # Tensor 데이터 타입으로 변경\n",
    "    transforms.Resize(32), # 이미지 사이즈를 28 > 32 로 변형 (renet 모델에서 32 사이즈 이미지를 사용하기 때문에)\n",
    "    transforms.Normalize((0.5),(1.0)) # 평균, 표준편차 | 실전에서는 전체 데이터셋의 평균과 표준편차를 계산하여 넣습니다\n",
    "])\n",
    "\n",
    "train_data = MNIST(root='./', train=True, download=True, transform=data_transform) \n",
    "test_data = MNIST(root='./', train=False, download=True, transform=data_transform) \n",
    "# transform : 데이터 전처리함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e7a302",
   "metadata": {},
   "source": [
    "## 2. 데이터 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd93554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b01d39e",
   "metadata": {},
   "source": [
    "## 3. 배치 사이즈에 따른 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b61d6ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True) \n",
    "test_loader = DataLoader(test_data, batch_size=32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239cd32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = next(iter(train_loader))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6196a2ba",
   "metadata": {},
   "source": [
    "## 4. 모델 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fe67ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lenet(nn.Module): # 📌 모델명(nn.Module) , 괄호 안에 nn.Module 을 반드시 적을 것\n",
    "    def __init__(self): # 📌 __init__(self) 를 반드시 해야함\n",
    "        super(Lenet, self).__init__() # 📌 super(모델명, self).__init__() 반드시 해야함\n",
    "\n",
    "        # convolutions 합성곱을 위한 함수들을 준비한다\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1)\n",
    "\n",
    "        # fully connection \n",
    "        self.fc1 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc2 = nn.Linear(in_features=84, out_features=10) \n",
    "        # ⭐⭐ 마지막 fc함수의 out_features 에는 내가 분류하고 싶은 정답을 적을것!!\n",
    "    \n",
    "    # ⭐ 순전파를 하는 함수\n",
    "    def forward(self, x):  # 📌 forward 안에 self 를 반드시 적어야함\n",
    "        x = self.conv1(x)                          \n",
    "        x = F.tanh(x) # 활성함수\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2) # 이미지 사이즈 축소\n",
    "\n",
    "        x = self.conv2(x)                            \n",
    "        x = F.tanh(x) # 활성함수\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2) # 이미지 사이즈 축소\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.tanh(x)\n",
    "\n",
    "        x = torch.reshape(x, (-1, 120)) # 이미지 평탄화\n",
    "\n",
    "        x = self.fc1(x)             # 선형함수\n",
    "        x = F.tanh(x)               # 활성함수\n",
    "\n",
    "        x = self.fc2(x)             # 선형함수\n",
    "        x = F.tanh(x)               # 활성함수 \n",
    "        # Renet 모델이 옛날 모델이라 tanh 활성함수를 마지막에 사용 중인데\n",
    "        # 최근 트렌드는 CrossEntrophy를 손실함수로 사용할 경우 마지막에 활성함수를 사용하지 않는다\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "208f7059",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lenet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de39a36",
   "metadata": {},
   "source": [
    "## 5. 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c9ec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, input_size=(1, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257dc4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모두 gpu에 올라가게 하는 코드\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554f785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "lr = 1e-3                               # ✅ 러닝레이트: 일반적으로 0.001 ~ 0.003\n",
    "optim = Adam(model.parameters(), lr=lr) # 파라미터 업데이트 최적화 알고리즘\n",
    "epochs = 10                             # ✅ 학습 반복 횟수\n",
    "criterion = nn.CrossEntropyLoss()       # ✅ 손실 함수 : 분류모델 - nn.CrossEntropyLoss() / 다른 모델 - nn.MSELoss\n",
    "\n",
    "step = 0\n",
    "for epoch in range(epochs):\n",
    "    # data : 32개의 이미지 데이터 / label : 32개의 이미지의 정답 데이터\n",
    "    for data, label in train_loader: # [(data, label)]\n",
    "        optim.zero_grad() # 📌 최적화 함수를 초기화 해야함 (한 번 학습시 마다)\n",
    "\n",
    "        # ⭐⭐ CNN 의 경우는 이미지의 채널 수만 맞추면 된다\n",
    "        # Renet 의 경우 1 채널 이미지만 되면 된다!\n",
    "        # 1) 순전파\n",
    "        pred = model(data.to(device)) # ⭐데이터 위치 체크\n",
    "\n",
    "        # 2) 손실 계산\n",
    "        loss = criterion(pred, label.to(device)) # ⭐데이터 위치 체크\n",
    "\n",
    "        # 3) 역전파\n",
    "        loss.backward()\n",
    "        optim.step() # 4) 파라미터 업데이트\n",
    "\n",
    "        # tensorboard에 데이터 추가\n",
    "        writer.add_scalar(\"Loss/train\", loss.item(), step)\n",
    "        step += 1\n",
    "\n",
    "    print(f\"{epoch + 1} loss : {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea6aa91",
   "metadata": {},
   "source": [
    "## 6. 모델 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508bd18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📌 ⭐⭐⭐ 학습시킨 모델이 날라가지 않도록 반드시 꼭꼭 저장하자\n",
    "import joblib\n",
    "\n",
    "# 모델 저장\n",
    "joblib.dump(model, 'models/number_image_cnn_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517f940f",
   "metadata": {},
   "source": [
    "## 7. 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8ba077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "import joblib\n",
    "model = joblib.load('models/number_image_cnn_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aefd996",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() # 📌 모델을 추론용으로 전환하게 하는 코드\n",
    "\n",
    "# 추가 작성 코드\n",
    "# falut_data = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_corr = 0\n",
    "    for images, labels in test_loader:\n",
    "        X = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        preds = model(X)\n",
    "        _, pred = torch.max(preds.data, dim = 1)\n",
    "        \n",
    "        result = (pred == labels)\n",
    "        total_corr += (result).sum().item()\n",
    "\n",
    "        # 추가 작성 코드\n",
    "        # for i, re in enumerate(result):\n",
    "        #     if re == False:\n",
    "        #         falut_data.append({\n",
    "        #             'image' : images[i],\n",
    "        #             'pred' : pred[i],\n",
    "        #             'label' :labels[i]\n",
    "        #         })\n",
    "\n",
    "print(f'정확도 : {total_corr / len(test_data.targets)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fb2674",
   "metadata": {},
   "source": [
    "## 8. 모델 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe08a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "image_path = 'images/4.jpg'\n",
    "\n",
    "# 1) 이미지 변환(transform) 파이프라인 정의\n",
    "# PyTorch 모델에 입력하기 위해 이미지를 텐서로 변환하는 과정을 정의\n",
    "# ToTensor()는 PIL Image를 PyTorch 텐서로 변환하며, 픽셀 값을 [0, 1] 범위로 정규화\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),              # 이미지를 PyTorch 텐서로 변환\n",
    "    transforms.Grayscale(),             # 이미지를 흑백으로 만든다\n",
    "    transforms.Resize((32, 32)),        # 이미지를 리사이즈\n",
    "    transforms.Normalize((0.5),(1.0))   # 평균, 표준편차로 정규화 한다\n",
    "])\n",
    "\n",
    "with Image.open(image_path) as image:\n",
    "        print(f\"PIL Image 크기: {image.size}\")\n",
    "        print(f\"PIL Image 모드: {image.mode}\")\n",
    "\n",
    "        image = image.convert('L')\n",
    "        \n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "        # 2) 정의한 변환(transform)을 이미지에 적용\n",
    "        tensor_image = transform(image)\n",
    "\n",
    "print(\"\\n이미지를 텐서로 변환 완료:\")\n",
    "print(f\"텐서 크기(size): {tensor_image.size}\")\n",
    "print(f\"텐서 데이터 타입: {tensor_image.dtype}\")\n",
    "\n",
    "# 3) 모델 예측\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "# ⭐⭐⭐ 0번째에 강제로 차원을 하나 추가한다\n",
    "# 왜? 이 모델에는 4차원데이터가 들어가야하니까\n",
    "# 기존에는 32개의 이미지에 대해서 1채널의 32 x 32 이미지가 담긴\n",
    "# (32, 1, 32, 32) 형태의 데이터를 모델에 넣었다\n",
    "\n",
    "# 지금은 1개의 이미지에 대해서 1채널의 32 32 이미지를 모델에 넣고싶으니\n",
    "# (1, 1, 32, 32) 형태의 데이터를 넣으면 된다\n",
    "tensor_image = tensor_image.unsqueeze(dim=0)\n",
    "preds = model(tensor_image.to(device))\n",
    "_, pred = torch.max(preds.data, dim=1)\n",
    "print(f\"예측 결과: {pred.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning-Study (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
